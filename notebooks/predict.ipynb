{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Test Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocess.py:63: RuntimeWarning: divide by zero encountered in log\n",
      "  log_duration = np.log(duration)\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# 5 Simulated sentences #\n",
    "#########################\n",
    "\n",
    "samp_freq = 10\n",
    "max_len = 200\n",
    "input_vocab_size = 500\n",
    "d_lower, d_upper = 0., 100. \n",
    "d_mu, d_sigma = 30., 10.\n",
    "min_frame_len = 10\n",
    "asn_upper = np.log(.95 * d_upper)\n",
    "asn_lower = np.log(min_frame_len/1000.)\n",
    "num_buckets = 50\n",
    "inc = (asn_upper - asn_lower)/(num_buckets-2)\n",
    "sen_n = 1\n",
    "batch_size = 1\n",
    "\n",
    "duration_test_sen = [create_duration_sentence(max_len,input_vocab_size,d_lower, d_upper, d_mu, d_sigma, \n",
    "                            asn_upper, asn_lower, num_buckets, batch_size) for i in range(sen_n/batch_size)]\n",
    "\n",
    "max_len = 512\n",
    "voiced_thresh = 1000.\n",
    "lower,upper = -5000.,5000.\n",
    "mu,sigma = 0., 500.\n",
    "sen_n = 5\n",
    "\n",
    "frequency_test_sen = [create_frequency_sentence(max_len,input_vocab_size,mu,sigma,lower,upper,\n",
    "                                            input_vocab_size,voiced_thresh,batch_size) for i in range(sen_n/batch_size)]\n",
    "#print test_sentences[0]['durations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_model_path = \"../weights/train_duration_model_notebook/model.ckpt\"\n",
    "frequency_model_path = \"../weights/train_frequency_model_notebook/model.ckpt\"\n",
    "\n",
    "\n",
    "def duration_predict(model_path,sentences):\n",
    "    tf.reset_default_graph()\n",
    "    saver = tf.train.import_meta_graph(model_path+\".meta\")\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,model_path)\n",
    "        trans_params = tf.get_collection(\"trans_params\")[0] \n",
    "        for s in sentences:\n",
    "            pred_durations = sess.run(\"ReverseSequence_1:0\", feed_dict={            \n",
    "                                        \"p_phonemes:0\": s['phonemes'], \n",
    "                                        \"p_seq_len:0\": s['phonemes_seq_len'], \n",
    "                                        \"p_spk_ids:0\": np.ones((batch_size)),\n",
    "                                        \"p_params:0\":trans_params.eval()\n",
    "                                        })\n",
    "            s['pred_durations'] = pred_durations\n",
    "            s['phoneme_frames'] = phonemes_to_frames(s['phonemes'],pred_durations,samp_freq,asn_lower,inc)\n",
    "        return sentences\n",
    "\n",
    "    \n",
    "def frequency_predict(model_path,sentences):\n",
    "    tf.reset_default_graph()\n",
    "    saver = tf.train.import_meta_graph(model_path+\".meta\")\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,model_path)\n",
    "        for s in sentences:\n",
    "            pred_voiced, pred_f_zero = sess.run([\"voiced_probability_model_1/dense/Sigmoid:0\",\n",
    "                               \"f_zero_1/add_2:0\"], feed_dict={            \n",
    "                                \"p_phonemes:0\": s['phonemes'], \n",
    "                                \"p_seq_len:0\": s['phonemes_seq_len'], \n",
    "                                \"p_spk_ids:0\": np.ones((batch_size))\n",
    "                            })\n",
    "            s['pred_voiced'] = pred_voiced\n",
    "            s['pred_f_zero'] = pred_f_zero\n",
    "        return sentences\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../weights/train_duration_model_notebook/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../weights/train_frequency_model_notebook/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "d_test_result = duration_predict(duration_model_path,duration_test_sen)\n",
    "f_test_result = frequency_predict(frequency_model_path,frequency_test_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport sys\\nsys.path.append(\"..\")\\nimport os\\nimport tensorflow as tf\\nimport numpy as np\\nfrom preprocess import *\\n\\nmodel_path = \\'../weights/train_grapheme_to_phoneme_model_notebook/model.ckpt\\'\\ndef predict(model_path):\\n    tf.reset_default_graph()\\n    saver = tf.train.import_meta_graph(model_path+\".meta\")\\n    graph = tf.get_default_graph()\\n\\n    with tf.Session() as sess:\\n        saver.restore(sess,model_path)\\n        pred = sess.run(prediction_tf, feed_dict={            \\n                                \"pred_ch\": np.random.rand(2, 200),\\n                                \"pred_ch_n\": 10* np.ones((2))\\n                            })\\n        return pred\\nprint predict(model_path)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from preprocess import *\n",
    "\n",
    "model_path = '../weights/train_grapheme_to_phoneme_model_notebook/model.ckpt'\n",
    "def predict(model_path):\n",
    "    tf.reset_default_graph()\n",
    "    saver = tf.train.import_meta_graph(model_path+\".meta\")\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,model_path)\n",
    "        pred = sess.run(prediction_tf, feed_dict={            \n",
    "                                \"pred_ch\": np.random.rand(2, 200),\n",
    "                                \"pred_ch_n\": 10* np.ones((2))\n",
    "                            })\n",
    "        return pred\n",
    "print predict(model_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
