{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.io import wavfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Real audio data\"\"\"\n",
    "\n",
    "wav_file = \"../data/wav48/p225/p225_001.wav\"\n",
    "\n",
    "# sample frequency: sample n frames in 1 second\n",
    "sampFreq ,snd = wavfile.read(wav_file)\n",
    "frame_n = len(snd)\n",
    "snd_len = 1. * frame_n / sampFreq\n",
    "\n",
    "timeArray = np.arange(0, frame_n, 1)\n",
    "timeArray = 1. * timeArray / sampFreq\n",
    "timeArray = timeArray * 1000  #scale to milliseconds\n",
    "print sampFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Simulated data\"\"\"\n",
    "\n",
    "# Durations \n",
    "phoneme_n = 10\n",
    "d_lower, d_upper = 0., 100.  #\n",
    "d_mu, d_sigma = 40., 20.\n",
    "samples = stats.truncnorm.rvs(\n",
    "          (d_lower-d_mu)/d_sigma,(d_upper-d_mu)/d_sigma,loc=d_mu,scale=d_sigma,size=phoneme_n)\n",
    "norm = 1. * samples / sum(samples)\n",
    "\n",
    "\n",
    "duration_per_phoneme = np.array([norm * snd_len]*2) # the time that each phoneme lasts\n",
    "frames_per_phoneme = np.array([[int(n) for n in norm * frame_n]]*2) # the frames that each phoneme contains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters\"\"\"\n",
    "\n",
    "# The params for bucket assignment\n",
    "# Each frame is ensured to be 10 milliseconds\n",
    "\n",
    "num_buckets = 256\n",
    "min_frame_len = 10\n",
    "asn_upper = np.log(.95 * d_upper)\n",
    "asn_lower = np.log(min_frame_len/1000.)\n",
    "inc = (asn_upper - asn_lower)/(num_buckets-2)\n",
    "\n",
    "# Wae file params\n",
    "#samp_freq = 10\n",
    "\n",
    "# The params for voiced tag\n",
    "voiced_thresh = 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Simulating Functions\"\"\"\n",
    "def generate_phonemes(max_len, vocab_size):\n",
    "    phoneme_n = np.random.randint(max_len)\n",
    "    phonemes = np.random.randint(vocab_size,size=phoneme_n)\n",
    "    zeros = np.zeros((max_len-phoneme_n), dtype=np.int)\n",
    "    phonemes = np.concatenate((phonemes,zeros))\n",
    "    return phonemes, phoneme_n\n",
    "\n",
    "def generate_durations(max_len,phoneme_n, d_lower, d_upper, d_mu, d_sigma):\n",
    "    duration_per_phoneme = stats.truncnorm.rvs(\n",
    "              (d_lower-d_mu)/d_sigma,(d_upper-d_mu)/d_sigma,loc=d_mu,scale=d_sigma,size=phoneme_n)\n",
    "    zeros = np.zeros((max_len-phoneme_n))\n",
    "    duration_per_phoneme = np.concatenate((duration_per_phoneme,zeros))\n",
    "    return duration_per_phoneme\n",
    "\n",
    "\n",
    "\n",
    "def create_sentence(max_len,input_vocab_size,d_lower, d_upper, d_mu, d_sigma, asn_upper, asn_lower, num_buckets, batch_size):\n",
    "    # speaker id = 1\n",
    "    phonemes, phoneme_n = generate_phonemes(max_len,input_vocab_size)\n",
    "    duration_per_phoneme = generate_durations(max_len,phoneme_n, d_lower, d_upper, d_mu, d_sigma)\n",
    "    duration_per_phoneme = assign_bucket([duration_per_phoneme]*batch_size,, asn_upper, asn_lower, num_buckets)\n",
    "    sentence_dict = {'phonemes':[phonemes]*batch_size,\n",
    "                     'phonemes_seq_len': [phoneme_n]*batch_size,, \n",
    "                     'speaker_ids': 1 * np.ones((batch_size)), \n",
    "                     'durations': duration_per_phoneme\n",
    "                     }\n",
    "    return sentence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef tag_target_voiced(snd, frames_per_phoneme):\\n    # Check whether each frame is voiced\\n    # Arg durations should be real time durations\\n    snd = np.array(snd)\\n    start_f = 0\\n    for f_n in frames_per_phoneme:\\n        end_f = start_f + f_n\\n        phoneme = snd[start_f:end_f]\\n        if max(phoneme) >= voiced_thresh:\\n            snd[start_f:end_f] = 1\\n        else:\\n            snd[start_f:end_f] = 0\\n        start_f = end_f\\n    return snd\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Preprocessing Functions\"\"\"\n",
    "def generate_phonemes1(max_len, vocab_size):\n",
    "    #phoneme_n = np.random.randint(max_len)\n",
    "    phoneme_n = 10\n",
    "    phonemes = np.random.randint(vocab_size,size=phoneme_n)\n",
    "    #zeros = np.zeros((max_len-phoneme_n), dtype=np.int)\n",
    "    #phonemes = np.concatenate((phonemes,zeros))\n",
    "    return phonemes, phoneme_n\n",
    "\n",
    "def assign_bucket(durations, asn_upper, asn_lower, num_buckets):\n",
    "    # Assign durations into buckets. Duration shape should be (batch_n, sentence_len).     \n",
    "    inc = (asn_upper - asn_lower)/(num_buckets-2)\n",
    "    def assign(duration):\n",
    "        log_duration = np.log(duration)\n",
    "        if log_duration < asn_lower:\n",
    "            return 0\n",
    "        elif log_duration > asn_upper:\n",
    "            return num_buckets\n",
    "        else:\n",
    "            return int(math.ceil((log_duration-asn_lower)/inc))\n",
    "    bucket_durations = [[assign(d) for d in sentence] for sentence in durations]\n",
    "    return bucket_durations\n",
    "\n",
    "def get_durations(bucket_durations):\n",
    "    # Calculate the duration by the bucket\n",
    "    def get(bucket):\n",
    "        log_durations = asn_lower + bucket * inc\n",
    "        return np.e**log_durations\n",
    "    durations = [[get(d) for d in sentence] for sentence in bucket_durations]\n",
    "    return durations\n",
    "\n",
    "\n",
    "def tag_target_voiced(snd):\n",
    "    # Check whether each frame is voiced\n",
    "    # Arg durations should be real time durations\n",
    "    voiced = [1 if frame>voiced_thresh else 0 for frame in snd]\n",
    "    \n",
    "    return voiced\n",
    "\n",
    "\n",
    "def phonemes_to_frames(phonemes,frames_per_phoneme):\n",
    "    # Upsample the phonemes to frames\n",
    "    # frames_per_phoneme is given when trianing, and is infered during prediction\n",
    "    frames = []\n",
    "    zipped = np.dstack((phonemes,frames_per_phoneme))\n",
    "    for sentence in zipped:\n",
    "        for (phoneme,frames_n) in sentence:\n",
    "            frames.extend(np.ones(frames_n,dtype=np.int)*phoneme)\n",
    "    #frames = [np.ones(frames_n,dtype=np.int)*phoneme for (phoneme,frames_n) in sentence] for sentence in zipped]\n",
    "    return frames\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def tag_target_voiced(snd, frames_per_phoneme):\n",
    "    # Check whether each frame is voiced\n",
    "    # Arg durations should be real time durations\n",
    "    snd = np.array(snd)\n",
    "    start_f = 0\n",
    "    for f_n in frames_per_phoneme:\n",
    "        end_f = start_f + f_n\n",
    "        phoneme = snd[start_f:end_f]\n",
    "        if max(phoneme) >= voiced_thresh:\n",
    "            snd[start_f:end_f] = 1\n",
    "        else:\n",
    "            snd[start_f:end_f] = 0\n",
    "        start_f = end_f\n",
    "    return snd\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 44 44 ...,  4  4  4]\n"
     ]
    }
   ],
   "source": [
    "phonemes,_ = generate_phonemes(200, 50)\n",
    "frames = np.array(phonemes_to_frames([list(phonemes)]*2,frames_per_phoneme))\n",
    "print frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.])]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
